{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8049feacbf85105d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T16:36:13.033991Z",
     "start_time": "2023-11-06T16:10:09.609866Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing former patch, files processed: 100%|██████████| 9208/9208 [00:46<00:00, 198.82it/s]\n",
      "Processing latter patch, files processed: 100%|██████████| 9218/9218 [00:46<00:00, 196.93it/s]\n",
      "Finding differences per character: 100%|██████████| 1991/1991 [00:12<00:00, 159.35it/s]\n",
      "Processing former patch, files processed: 100%|██████████| 9208/9208 [00:46<00:00, 199.77it/s]\n",
      "Processing latter patch, files processed: 100%|██████████| 9231/9231 [00:50<00:00, 183.55it/s]\n",
      "Finding differences per character: 100%|██████████| 1996/1996 [01:35<00:00, 20.88it/s] \n",
      "Processing former patch, files processed: 100%|██████████| 9208/9208 [00:44<00:00, 205.99it/s]\n",
      "Processing latter patch, files processed: 100%|██████████| 9234/9234 [00:50<00:00, 183.52it/s]\n",
      "Finding differences per character: 100%|██████████| 1996/1996 [04:57<00:00,  6.71it/s]\n",
      "Processing former patch, files processed: 100%|██████████| 9218/9218 [00:45<00:00, 204.01it/s]\n",
      "Processing latter patch, files processed: 100%|██████████| 9231/9231 [00:50<00:00, 182.16it/s]\n",
      "Finding differences per character: 100%|██████████| 1996/1996 [01:22<00:00, 24.07it/s]\n",
      "Processing former patch, files processed: 100%|██████████| 9218/9218 [00:45<00:00, 204.80it/s]\n",
      "Processing latter patch, files processed: 100%|██████████| 9234/9234 [00:50<00:00, 181.16it/s]\n",
      "Finding differences per character: 100%|██████████| 1996/1996 [04:48<00:00,  6.91it/s]\n",
      "Processing former patch, files processed: 100%|██████████| 9231/9231 [00:51<00:00, 179.69it/s]\n",
      "Processing latter patch, files processed: 100%|██████████| 9234/9234 [00:52<00:00, 176.52it/s]\n",
      "Finding differences per character: 100%|██████████| 1996/1996 [03:25<00:00,  9.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from html2text import html2text\n",
    "from collections import defaultdict\n",
    "from fuzzywuzzy import fuzz\n",
    "from time import sleep\n",
    "import pickle\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    return re.findall(r'\\b\\w[\\w\\'-]*\\b|\\s+|[.,!?;]', text)\n",
    "\n",
    "\n",
    "def highlight_differences(old_str, new_str):\n",
    "    old_words = split_text(old_str)\n",
    "    new_words = split_text(new_str)\n",
    "\n",
    "    matcher = SequenceMatcher(None, old_words, new_words)\n",
    "    diff = list(matcher.get_opcodes())\n",
    "\n",
    "    highlighted_old = []\n",
    "    highlighted_new = []\n",
    "\n",
    "    for opcode, a1, a2, b1, b2 in diff:\n",
    "        if opcode in ('replace', 'insert'):\n",
    "            highlighted_new.extend(['<span style=\"color: green;\">{}</span>'.format(word) for word in new_words[b1:b2]])\n",
    "        if opcode in ('replace', 'delete'):\n",
    "            highlighted_old.extend(['<span style=\"color: red;\">{}</span>'.format(word) for word in old_words[a1:a2]])\n",
    "        else:\n",
    "            highlighted_old.extend(old_words[a1:a2])\n",
    "            highlighted_new.extend(new_words[b1:b2])\n",
    "\n",
    "    highlighted_old_str = ''.join(highlighted_old)\n",
    "    highlighted_new_str = ''.join(highlighted_new)\n",
    "\n",
    "    return highlighted_old_str, highlighted_new_str\n",
    "\n",
    "\n",
    "def read_patch_dialogs(patch_former, patch_latter):\n",
    "    dialogue_files_former = list(glob(f\"data/{patch_former}/**/*.html\", recursive=True))\n",
    "    dialogue_files_latter = list(glob(f\"data/{patch_latter}/**/*.html\", recursive=True))\n",
    "\n",
    "    former_lines_dict = defaultdict(set)\n",
    "    latter_lines_dict = defaultdict(set)\n",
    "\n",
    "    f_lines_count = 0\n",
    "    for fn in tqdm(dialogue_files_former, desc=f\"Processing former patch, files processed\"):\n",
    "        file = open(fn, \"r\", encoding='latin-1')\n",
    "        index = file.read()\n",
    "        source = BeautifulSoup(index, 'lxml')\n",
    "        div_elements = source.find_all('div', class_=\"npc\")\n",
    "        for div_element in div_elements:\n",
    "            character = div_element.text\n",
    "            dialog_span = div_element.find_next('span', class_='dialog')\n",
    "            former_lines_dict[character].add(html2text(str(dialog_span)).strip())\n",
    "            f_lines_count += 1\n",
    "\n",
    "    l_lines_count = 0\n",
    "    for fn in tqdm(dialogue_files_latter, desc=f\"Processing latter patch, files processed\"):\n",
    "        file = open(fn, \"r\", encoding='latin-1')\n",
    "        index = file.read()\n",
    "        source = BeautifulSoup(index, 'lxml')\n",
    "        div_elements = source.find_all('div', class_=\"npc\")\n",
    "        for div_element in div_elements:\n",
    "            character = div_element.text\n",
    "            dialog_span = div_element.find_next('span', class_='dialog')\n",
    "            latter_lines_dict[character].add(html2text(str(dialog_span)).strip())\n",
    "            l_lines_count += 1\n",
    "\n",
    "    return former_lines_dict, latter_lines_dict\n",
    "\n",
    "\n",
    "def calculate_differences(former_patch_name, latter_patch_name, former_lines_dict, latter_lines_dict):\n",
    "    all_characters = set(list(former_lines_dict.keys()) + list(latter_lines_dict.keys()))\n",
    "    char_lines_dict = defaultdict(dict)\n",
    "    for character in tqdm(all_characters, desc=\"Finding differences per character\"):\n",
    "        lines = [l for l in latter_lines_dict[character] if l not in former_lines_dict[character]]\n",
    "        new_lines = set()\n",
    "        changed_lines = []\n",
    "        for line in lines:\n",
    "            for old_line in former_lines_dict[character]:\n",
    "                if fuzz.ratio(line, old_line) > 80:\n",
    "                    changed_lines.append((old_line, line))\n",
    "                    break\n",
    "            else:\n",
    "                new_lines.add(line)\n",
    "                \n",
    "        if len(changed_lines) > 0 or len(new_lines) > 0:\n",
    "            char_lines_dict[character][\"changed\"] = changed_lines\n",
    "            char_lines_dict[character][\"new\"] = new_lines\n",
    "    \n",
    "    with open(f\"cache/cd_{former_patch_name}-{latter_patch_name}.pkl\", 'wb') as file:\n",
    "        pickle.dump(char_lines_dict, file)\n",
    "            \n",
    "\n",
    "patches = [v.replace(\"\\\\\", '/').split('/')[1] for v in glob(\"data/*\") if \"Parser\" not in v]\n",
    "patches.sort()\n",
    "former_patch_index = 0    \n",
    "\n",
    "for i in range(len(patches)):\n",
    "    for j in range(i + 1, len(patches)):\n",
    "        former_patch = patches[i]\n",
    "        latter_patch = patches[j]\n",
    "        former_patch_name = former_patch.split(' - ')[0]\n",
    "        latter_patch_name = latter_patch.split(' - ')[0]\n",
    "        if os.path.isfile(f\"cache/cd_{former_patch_name}-{latter_patch_name}.pkl\"):\n",
    "            continue\n",
    "        \n",
    "        former, latter = read_patch_dialogs(former_patch, latter_patch)\n",
    "        calculate_differences(former_patch_name, latter_patch_name, former, latter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3062cc82d9c3cbc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
