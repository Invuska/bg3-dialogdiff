{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8049feacbf85105d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:05:12.331256800Z",
     "start_time": "2023-11-30T21:37:21.104532200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing former patch, files processed: 100%|██████████| 9208/9208 [01:42<00:00, 90.23it/s] \n",
      "Processing latter patch, files processed: 100%|██████████| 9218/9218 [01:43<00:00, 88.64it/s] \n",
      "Finding differences per character:  65%|██████▍   | 1290/1991 [24:24<13:15,  1.14s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 119\u001B[0m\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m    118\u001B[0m former, latter \u001B[38;5;241m=\u001B[39m read_patch_dialogs(former_patch, latter_patch)\n\u001B[1;32m--> 119\u001B[0m calculate_differences(former_patch_name, latter_patch_name, former, latter)\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[5], line 90\u001B[0m, in \u001B[0;36mcalculate_differences\u001B[1;34m(former_patch_name, latter_patch_name, former_lines_dict, latter_lines_dict)\u001B[0m\n\u001B[0;32m     88\u001B[0m old_fn, old_line \u001B[38;5;241m=\u001B[39m old_line_info\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m||||\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     89\u001B[0m bn, old_bn \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(fn), os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(old_fn)\n\u001B[1;32m---> 90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fuzz\u001B[38;5;241m.\u001B[39mratio(line, old_line) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m80\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m bn \u001B[38;5;241m==\u001B[39m old_bn:\n\u001B[0;32m     91\u001B[0m     changed_lines\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfn\u001B[39m\u001B[38;5;124m\"\u001B[39m: fn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlines\u001B[39m\u001B[38;5;124m\"\u001B[39m: (old_line, line)})\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bg3_tools\\Lib\\site-packages\\fuzzywuzzy\\utils.py:38\u001B[0m, in \u001B[0;36mcheck_for_none.<locals>.decorator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m args[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 38\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bg3_tools\\Lib\\site-packages\\fuzzywuzzy\\utils.py:29\u001B[0m, in \u001B[0;36mcheck_for_equivalence.<locals>.decorator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m args[\u001B[38;5;241m1\u001B[39m]:\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bg3_tools\\Lib\\site-packages\\fuzzywuzzy\\utils.py:47\u001B[0m, in \u001B[0;36mcheck_empty_string.<locals>.decorator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bg3_tools\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:28\u001B[0m, in \u001B[0;36mratio\u001B[1;34m(s1, s2)\u001B[0m\n\u001B[0;32m     25\u001B[0m s1, s2 \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mmake_type_consistent(s1, s2)\n\u001B[0;32m     27\u001B[0m m \u001B[38;5;241m=\u001B[39m SequenceMatcher(\u001B[38;5;28;01mNone\u001B[39;00m, s1, s2)\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mintr(\u001B[38;5;241m100\u001B[39m \u001B[38;5;241m*\u001B[39m m\u001B[38;5;241m.\u001B[39mratio())\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\bg3_tools\\Lib\\site-packages\\fuzzywuzzy\\utils.py:103\u001B[0m, in \u001B[0;36mintr\u001B[1;34m(n)\u001B[0m\n\u001B[0;32m     99\u001B[0m     string_out \u001B[38;5;241m=\u001B[39m StringProcessor\u001B[38;5;241m.\u001B[39mstrip(string_out)\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m string_out\n\u001B[1;32m--> 103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mintr\u001B[39m(n):\n\u001B[0;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Returns a correctly rounded integer'''\u001B[39;00m\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mround\u001B[39m(n))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from html2text import html2text\n",
    "from collections import defaultdict\n",
    "from fuzzywuzzy import fuzz\n",
    "from time import sleep\n",
    "import pickle\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    return re.findall(r'\\b\\w[\\w\\'-]*\\b|\\s+|[.,!?;]', text)\n",
    "\n",
    "\n",
    "def highlight_differences(old_str, new_str):\n",
    "    old_words = split_text(old_str)\n",
    "    new_words = split_text(new_str)\n",
    "\n",
    "    matcher = SequenceMatcher(None, old_words, new_words)\n",
    "    diff = list(matcher.get_opcodes())\n",
    "\n",
    "    highlighted_old = []\n",
    "    highlighted_new = []\n",
    "\n",
    "    for opcode, a1, a2, b1, b2 in diff:\n",
    "        if opcode in ('replace', 'insert'):\n",
    "            highlighted_new.extend(['<span style=\"color: green;\">{}</span>'.format(word) for word in new_words[b1:b2]])\n",
    "        if opcode in ('replace', 'delete'):\n",
    "            highlighted_old.extend(['<span style=\"color: red;\">{}</span>'.format(word) for word in old_words[a1:a2]])\n",
    "        else:\n",
    "            highlighted_old.extend(old_words[a1:a2])\n",
    "            highlighted_new.extend(new_words[b1:b2])\n",
    "\n",
    "    highlighted_old_str = ''.join(highlighted_old)\n",
    "    highlighted_new_str = ''.join(highlighted_new)\n",
    "\n",
    "    return highlighted_old_str, highlighted_new_str\n",
    "\n",
    "\n",
    "def read_patch_dialogs(patch_former, patch_latter):\n",
    "    dialogue_files_former = list(glob(f\"data/{patch_former}/**/*.html\", recursive=True))\n",
    "    dialogue_files_latter = list(glob(f\"data/{patch_latter}/**/*.html\", recursive=True))\n",
    "\n",
    "    former_lines_dict = defaultdict(set)\n",
    "    latter_lines_dict = defaultdict(set)\n",
    "\n",
    "    f_lines_count = 0\n",
    "    for fn in tqdm(dialogue_files_former, desc=f\"Processing former patch, files processed\"):\n",
    "        file = open(fn, \"r\", encoding='latin-1')\n",
    "        index = file.read()\n",
    "        source = BeautifulSoup(index, 'lxml')\n",
    "        div_elements = source.find_all('div', class_=\"npc\")\n",
    "        for div_element in div_elements:\n",
    "            character = div_element.text\n",
    "            dialog_span = div_element.find_next('span', class_='dialog')\n",
    "            former_lines_dict[character].add(f\"{fn}||||{html2text(str(dialog_span)).strip()}\")\n",
    "            f_lines_count += 1\n",
    "\n",
    "    l_lines_count = 0\n",
    "    for fn in tqdm(dialogue_files_latter, desc=f\"Processing latter patch, files processed\"):\n",
    "        file = open(fn, \"r\", encoding='latin-1')\n",
    "        index = file.read()\n",
    "        source = BeautifulSoup(index, 'lxml')\n",
    "        div_elements = source.find_all('div', class_=\"npc\")\n",
    "        for div_element in div_elements:\n",
    "            character = div_element.text\n",
    "            dialog_span = div_element.find_next('span', class_='dialog')\n",
    "            latter_lines_dict[character].add(f\"{fn}||||{html2text(str(dialog_span)).strip()}\")\n",
    "            l_lines_count += 1\n",
    "\n",
    "    return former_lines_dict, latter_lines_dict\n",
    "\n",
    "\n",
    "def calculate_differences(former_patch_name, latter_patch_name, former_lines_dict, latter_lines_dict):\n",
    "    all_characters = set(list(former_lines_dict.keys()) + list(latter_lines_dict.keys()))\n",
    "    char_lines_dict = defaultdict(dict)\n",
    "    for character in tqdm(all_characters, desc=\"Finding differences per character\"):\n",
    "        lines = [l for l in latter_lines_dict[character] if l not in former_lines_dict[character]]\n",
    "        new_lines = []\n",
    "        changed_lines = []\n",
    "        for line_info in lines:\n",
    "            fn, line = line_info.split(\"||||\")\n",
    "            for old_line_info in former_lines_dict[character]:\n",
    "                old_fn, old_line = old_line_info.split(\"||||\")\n",
    "                bn, old_bn = os.path.basename(fn), os.path.basename(old_fn)\n",
    "                if fuzz.ratio(line, old_line) > 80 and bn == old_bn:\n",
    "                    changed_lines.append({\"fn\": fn, \"lines\": (old_line, line)})\n",
    "                    break\n",
    "            else:\n",
    "                new_lines.append({\"fn\": fn, \"line\": line})\n",
    "                \n",
    "        if len(changed_lines) > 0 or len(new_lines) > 0:\n",
    "            char_lines_dict[character][\"changed\"] = changed_lines\n",
    "            char_lines_dict[character][\"new\"] = new_lines\n",
    "    \n",
    "    with open(f\"cache/cd_{former_patch_name}-{latter_patch_name}.pkl\", 'wb') as file:\n",
    "        pickle.dump(char_lines_dict, file)\n",
    "            \n",
    "\n",
    "patches = [v.replace(\"\\\\\", '/').split('/')[1] for v in glob(\"data/*\") if \"Parser\" not in v]\n",
    "patches.sort()\n",
    "former_patch_index = 0    \n",
    "\n",
    "for i in range(len(patches)):\n",
    "    for j in range(i + 1, len(patches)):\n",
    "        former_patch = patches[i]\n",
    "        latter_patch = patches[j]\n",
    "        former_patch_name = former_patch.split(' - ')[0]\n",
    "        latter_patch_name = latter_patch.split(' - ')[0]\n",
    "        print(former_patch_name, latter_patch_name)\n",
    "        if os.path.isfile(f\"cache/cd_{former_patch_name}-{latter_patch_name}.pkl\"):\n",
    "            continue\n",
    "        \n",
    "        former, latter = read_patch_dialogs(former_patch, latter_patch)\n",
    "        calculate_differences(former_patch_name, latter_patch_name, former, latter)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.2\n",
      "1.0 1.3\n",
      "1.0 1.4\n",
      "1.0 1.5\n",
      "1.0 1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding differences per character: 100%|██████████| 2008/2008 [08:04<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 1.3\n",
      "1.2 1.4\n",
      "1.2 1.5\n",
      "1.2 1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding differences per character: 100%|██████████| 2008/2008 [08:22<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 1.4\n",
      "1.3 1.5\n",
      "1.3 1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding differences per character: 100%|██████████| 2008/2008 [07:37<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4 1.5\n",
      "1.4 1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding differences per character: 100%|██████████| 2005/2005 [07:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding differences per character: 100%|██████████| 2005/2005 [01:55<00:00, 17.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from html2text import html2text\n",
    "from collections import defaultdict\n",
    "from fuzzywuzzy import fuzz\n",
    "from time import sleep\n",
    "import pickle\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "def split_text(text):\n",
    "    return re.findall(r'\\b\\w[\\w\\'-]*\\b|\\s+|[.,!?;]', text)\n",
    "\n",
    "\n",
    "def highlight_differences(old_str, new_str):\n",
    "    old_words = split_text(old_str)\n",
    "    new_words = split_text(new_str)\n",
    "\n",
    "    matcher = SequenceMatcher(None, old_words, new_words)\n",
    "    diff = list(matcher.get_opcodes())\n",
    "\n",
    "    highlighted_old = []\n",
    "    highlighted_new = []\n",
    "\n",
    "    for opcode, a1, a2, b1, b2 in diff:\n",
    "        if opcode in ('replace', 'insert'):\n",
    "            highlighted_new.extend(['<span style=\"color: green;\">{}</span>'.format(word) for word in new_words[b1:b2]])\n",
    "        if opcode in ('replace', 'delete'):\n",
    "            highlighted_old.extend(['<span style=\"color: red;\">{}</span>'.format(word) for word in old_words[a1:a2]])\n",
    "        else:\n",
    "            highlighted_old.extend(old_words[a1:a2])\n",
    "            highlighted_new.extend(new_words[b1:b2])\n",
    "\n",
    "    highlighted_old_str = ''.join(highlighted_old)\n",
    "    highlighted_new_str = ''.join(highlighted_new)\n",
    "\n",
    "    return highlighted_old_str, highlighted_new_str\n",
    "\n",
    "\n",
    "def read_patch_dialogs(patch_former, patch_latter):\n",
    "    dialogue_files_former = list(glob(f\"data/{patch_former}/**/*.html\", recursive=True))\n",
    "    dialogue_files_latter = list(glob(f\"data/{patch_latter}/**/*.html\", recursive=True))\n",
    "\n",
    "\n",
    "    \n",
    "    if not os.path.isfile(f\"data/read_caches/{patch_former}_former.pkl\"):\n",
    "        former_lines_dict = defaultdict(set)\n",
    "        former_lines_info_dict = defaultdict(set)\n",
    "        \n",
    "        f_lines_count = 0\n",
    "        for fn in tqdm(dialogue_files_former, desc=f\"Processing former patch, files processed\"):\n",
    "            file = open(fn, \"r\", encoding='latin-1')\n",
    "            index = file.read()\n",
    "            source = BeautifulSoup(index, 'lxml')\n",
    "            div_elements = source.find_all('div', class_=\"npc\")\n",
    "            for div_element in div_elements:\n",
    "                character = div_element.text\n",
    "                dialog_span = div_element.find_next('span', class_='dialog')\n",
    "                former_lines_dict[character].add(html2text(str(dialog_span)).strip())\n",
    "                former_lines_info_dict[character].add(f\"{fn}||||{html2text(str(dialog_span)).strip()}\")\n",
    "                f_lines_count += 1\n",
    "\n",
    "        former_pickle_dict = {\"f_lines_count\": f_lines_count, \n",
    "                              \"former_lines_dict\": former_lines_dict, \n",
    "                              \"former_lines_info_dict\": former_lines_info_dict}\n",
    "        with open(f\"data/read_caches/{patch_former}_former.pkl\", 'wb') as pickle_file:\n",
    "            pickle.dump(former_pickle_dict, pickle_file)\n",
    "    else:\n",
    "        with open(f\"data/read_caches/{patch_former}_former.pkl\", 'rb') as pickle_file:\n",
    "            former_pickle_dict = pickle.load(pickle_file)\n",
    "        f_lines_count, former_lines_dict, former_lines_info_dict = (former_pickle_dict[\"f_lines_count\"],\n",
    "                                                                   former_pickle_dict[\"former_lines_dict\"],\n",
    "                                                                   former_pickle_dict[\"former_lines_info_dict\"])\n",
    "\n",
    "    if not os.path.isfile(f\"data/read_caches/{patch_latter}_latter.pkl\"):\n",
    "        latter_lines_dict = defaultdict(set)\n",
    "        \n",
    "        l_lines_count = 0\n",
    "        for fn in tqdm(dialogue_files_latter, desc=f\"Processing latter patch, files processed\"):\n",
    "            file = open(fn, \"r\", encoding='latin-1')\n",
    "            index = file.read()\n",
    "            source = BeautifulSoup(index, 'lxml')\n",
    "            div_elements = source.find_all('div', class_=\"npc\")\n",
    "            for div_element in div_elements:\n",
    "                character = div_element.text\n",
    "                dialog_span = div_element.find_next('span', class_='dialog')\n",
    "                latter_lines_dict[character].add(f\"{fn}||||{html2text(str(dialog_span)).strip()}\")\n",
    "                l_lines_count += 1\n",
    "                \n",
    "        latter_pickle_dict = {\"l_lines_count\": l_lines_count, \n",
    "                              \"latter_lines_dict\": latter_lines_dict}\n",
    "        with open(f\"data/read_caches/{patch_latter}_latter.pkl\", 'wb') as pickle_file:\n",
    "            pickle.dump(latter_pickle_dict, pickle_file)\n",
    "    else:\n",
    "        with open(f\"data/read_caches/{patch_latter}_latter.pkl\", 'rb') as pickle_file:\n",
    "            latter_pickle_dict = pickle.load(pickle_file)\n",
    "        l_lines_count, latter_lines_dict = (latter_pickle_dict[\"l_lines_count\"],\n",
    "                                           latter_pickle_dict[\"latter_lines_dict\"])\n",
    "\n",
    "    return former_lines_info_dict, former_lines_dict, latter_lines_dict\n",
    "\n",
    "\n",
    "def calculate_differences(former_patch_name, latter_patch_name, former_lines_info_dict, former_lines_dict, latter_lines_dict):\n",
    "    all_characters = set(list(former_lines_dict.keys()) + list(latter_lines_dict.keys()))\n",
    "    char_lines_dict = defaultdict(dict)\n",
    "    \n",
    "    def process_line(index, line_info, former_lines_info_dict, character):\n",
    "        fn, line = line_info.split(\"||||\")\n",
    "        for old_line_info in former_lines_info_dict[character]:\n",
    "            old_fn, old_line = old_line_info.split(\"||||\")\n",
    "            bn, old_bn = os.path.basename(fn), os.path.basename(old_fn)\n",
    "            if fuzz.ratio(line, old_line) > 80 and bn == old_bn:\n",
    "                return index, {\"type\": \"changed\", \"fn\": fn, \"lines\": (old_line, line)}\n",
    "        return index, {\"type\": \"new\", \"fn\": fn, \"line\": line}\n",
    "    \n",
    "    for character in tqdm(all_characters, desc=\"Finding differences per character\"):\n",
    "        lines = [l for l in latter_lines_dict[character] if l.split(\"||||\")[1] not in former_lines_dict[character]]\n",
    "        results = Parallel(n_jobs=-1)(delayed(process_line)(i, line_info, former_lines_info_dict, character) for i, line_info in enumerate(lines))\n",
    "        new_lines = [result[1] for result in sorted(results) if result[1][\"type\"] == \"new\"]\n",
    "        changed_lines = [result[1] for result in sorted(results) if result[1][\"type\"] == \"changed\"]\n",
    "\n",
    "        if len(changed_lines) > 0 or len(new_lines) > 0:\n",
    "            char_lines_dict[character][\"changed\"] = changed_lines\n",
    "            char_lines_dict[character][\"new\"] = new_lines\n",
    "    \n",
    "    with open(f\"cache/cd_{former_patch_name}-{latter_patch_name}.pkl\", 'wb') as file:\n",
    "        pickle.dump(char_lines_dict, file)\n",
    "            \n",
    "\n",
    "patches = [v.replace(\"\\\\\", '/').split('/')[1] for v in glob(\"data/*\") if all([\"Parser\" not in v,\n",
    "                                                                              \"read_caches\" not in v])]\n",
    "patches.sort()\n",
    "former_patch_index = 0    \n",
    "\n",
    "for i in range(len(patches)):\n",
    "    for j in range(i + 1, len(patches)):\n",
    "        former_patch = patches[i]\n",
    "        latter_patch = patches[j]\n",
    "        former_patch_name = former_patch.split(' - ')[0]\n",
    "        latter_patch_name = latter_patch.split(' - ')[0]\n",
    "        print(former_patch_name, latter_patch_name)\n",
    "        if os.path.isfile(f\"cache/cd_{former_patch_name}-{latter_patch_name}.pkl\"):\n",
    "            continue\n",
    "        \n",
    "        former_info, former, latter = read_patch_dialogs(former_patch, latter_patch)\n",
    "        calculate_differences(former_patch_name, latter_patch_name, former_info, former, latter)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T12:32:35.973451100Z",
     "start_time": "2024-02-17T11:59:34.142822300Z"
    }
   },
   "id": "360b668982756fa9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "patch_former = \"1.0 - Launch Day\"\n",
    "patch_latter = \"1.6 - Patch 6\"\n",
    "\n",
    "with open(f\"data/read_caches/{patch_former}_former.pkl\", 'rb') as pickle_file:\n",
    "    former_pickle_dict = pickle.load(pickle_file)\n",
    "f_lines_count, former_lines_dict, former_lines_info_dict = (former_pickle_dict[\"f_lines_count\"],\n",
    "former_pickle_dict[\"former_lines_dict\"],\n",
    "former_pickle_dict[\"former_lines_info_dict\"])\n",
    "\n",
    "with open(f\"data/read_caches/{patch_latter}_latter.pkl\", 'rb') as pickle_file:\n",
    "    latter_pickle_dict = pickle.load(pickle_file)\n",
    "l_lines_count, latter_lines_dict = (latter_pickle_dict[\"l_lines_count\"],\n",
    "                                           latter_pickle_dict[\"latter_lines_dict\"])\n",
    "    \n",
    "print(f_lines_count, l_lines_count)\n",
    "all_characters = set(list(former_lines_dict.keys()) + list(latter_lines_dict.keys()))\n",
    "print(len(all_characters))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cdf7e5ba4e33f10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(list(all_characters))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d60b6e7d6bee3ec2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(\"9ff83d30-3dc9-4fde-b173-7cc83914baf6\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7e64dd0fd5b5606"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for c in all_characters:\n",
    "    if len(c) > 30:\n",
    "        print(c)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8a71932048c64f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ac2 = set()\n",
    "for c in all_characters:\n",
    "    if len(c) > 35 and '-' in c:\n",
    "        pass\n",
    "    elif \"_\" in c:\n",
    "        pass\n",
    "    elif \", \" in c:\n",
    "        cs = c.split(\", \")\n",
    "        for ci in cs:\n",
    "            ac2.add(ci)\n",
    "    else:\n",
    "        ac2.add(c)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78d6212f120d22d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(ac2))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "301ecb07b201f4b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(ac2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a60c792c869ff944"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(\"77595417-3b1f-48b7-9737-993b5da48c81\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "545d827d4df13b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "118d0a66c2409de4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
